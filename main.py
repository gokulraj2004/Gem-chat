import os

import streamlit as st
from dotenv import load_dotenv
import google.generativeai as gen_ai

#loading environment variable
load_dotenv()

#configuring streamlit page settings
st.set_page_config(
    page_icon='â­',
    page_title='ğŸ’GemChatğŸ’',
    layout='wide',
    menu_items={'Get Help': 'https://www.linkedin.com/in/gokulraj075/',
                'Report a bug': "https://www.linkedin.com/in/gokulraj075/",
                'About': "GOKUL RAJ.S | Junior Data Scientist | Proficient in Power BI, Advanced SQL, Python | Excel Expert | AZ-104 Certified | AZ-900 Certified | Google Cloud Certified 17+ Badges | Machine Learning | VIT 25"}
)



google_api=os.getenv("GOOGLE_API_KEY")

#Set up Google Gemini-Pro AI Model
gen_ai.configure(api_key=google_api)
model=gen_ai.GenerativeModel('gemini-pro')

#funcction to translate roles b/w gemini-pro and streamlit terminology
def translate_role_for_streamlit(user_role):
    if user_role=="model":
        return "assitant"
    else:
        return user_role

# Initialize chat session in streamlit if not already present
if "chat_session" not in st.session_state:
    st.session_state.chat_session = model.start_chat(history=[])
    
#Display the chatbot's title on the page
st.title("GemChat")
st.write("  ğ–  ğ–¼ğ—ğ–ºğ—ğ–»ğ—ˆğ— ğ–»ğ—ğ—‚ğ—…ğ— ğ—ğ—‚ğ—ğ— ğ–²ğ—ğ—‹ğ–¾ğ–ºğ—†ğ—…ğ—‚ğ—, ğ—ğ—Œğ—‚ğ—‡ğ—€ ğ—ğ—ğ–¾ ğ–¦ğ–¾ğ—†ğ—‚ğ—‡ğ—‚ ğ– ğ–¯ğ–¨ ğ—„ğ–¾ğ—’ ğ–¿ğ—ˆğ—‹ ğ—‚ğ—‡ğ—ğ–¾ğ—…ğ—…ğ—‚ğ—€ğ–¾ğ—‡ğ— ğ–ºğ—‡ğ–½ ğ—‹ğ–¾ğ—Œğ—‰ğ—ˆğ—‡ğ—Œğ—‚ğ—ğ–¾ ğ—‚ğ—‡ğ—ğ–¾ğ—‹ğ–ºğ–¼ğ—ğ—‚ğ—ˆğ—‡ğ—Œ.")

col1, col2 = st.columns([4, 1])

with col1:
        st.subheader("") 
with col2:
        st.subheader("Gokul Raj")
        st.write("Junior Data Scientist | Proficient in Power BI, Advanced SQL, Python | Excel Expert | AZ-104 & AZ-900 Certified | Google Cloud Certified with 17+ Badges | Machine Learning Enthusiast | VIT 2025") 
        #add_predictions(input_data)



#Display the chatbot history
for message in st.session_state.chat_session.history:
    with st.chat_message(translate_role_for_streamlit(message.role)):
        st.markdown(message.parts[0].text)
        
#input field for user's message
user_prompt=st.chat_input("Ask Gemini....")
if user_prompt:
    # Add user's message to chat and display it
    st.chat_message("user").markdown(user_prompt)
    
    #send user's message to gemini and get the response
    gem_resp=st.session_state.chat_session.send_message(user_prompt)

    #Display Gemini response
    with st.chat_message("assistant"):
        st.markdown(gem_resp.text)
        
